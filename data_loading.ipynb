{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classroom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from data.class_data import loaddata\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassroomDataset(Dataset):\n",
    "    \n",
    "    @staticmethod\n",
    "    def standardize_image(image):\n",
    "        expected_shape = (50,50)\n",
    "        padding = [(0,0), (0,0)]\n",
    "        cropping = [(0,50), (0, 50)]\n",
    "        for d in [0,1]:\n",
    "            exp = expected_shape[d]\n",
    "            act = image.shape[d]\n",
    "            diff = exp - act\n",
    "            if diff > 0:\n",
    "                padding[d] = (ceil(diff / 2), floor(diff / 2))\n",
    "            elif diff < 0:\n",
    "                diff *= -1\n",
    "                cropping[d] = (ceil(diff / 2), 50 + floor(diff / 2))\n",
    "        image = np.pad(image, padding, 'constant', constant_values=0)\n",
    "        y = cropping[0]\n",
    "        x = cropping[1]\n",
    "        image = image[y[0]:y[1], x[0]:x[1]]\n",
    "        return image\n",
    "    \n",
    "    def to_include(self, i):\n",
    "        ret = False\n",
    "        mx = self.range_10[1]\n",
    "        mn = self.range_10[0]\n",
    "        if i % 10 < mx and i % 10 >= mn:\n",
    "            ret = True\n",
    "        return ret\n",
    "    \n",
    "    def __init__(self, range_10=[0, 10]):\n",
    "        path = \"data/class_data/train_data.pkl\"\n",
    "        cls_data = loaddata.load_pkl(path)\n",
    "        labels = np.load(\"data/class_data/finalLabelsTrain.npy\") \n",
    "        self.data = []\n",
    "        self.range_10 = range_10\n",
    "        gpu = torch.cuda.is_available()\n",
    "#         gpu = False\n",
    "        for i in range(len(cls_data)):\n",
    "            if self.to_include(i): # train set\n",
    "                image = np.array(cls_data[i])\n",
    "                image = image.astype(int)\n",
    "                image = self.standardize_image(image)\n",
    "                image = torch.from_numpy(np.array([image])).float()\n",
    "                label = torch.tensor(int(labels[i]))\n",
    "                if gpu:\n",
    "                    image = image.cuda()\n",
    "                    label = label.cuda()\n",
    "                pair = (image, label)\n",
    "                self.data.append(pair)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_data = ClassroomDataset(range_10=[5,10])\n",
    "i = 0\n",
    "cls_data.__len__()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i += 1\n",
    "print(i)\n",
    "image, label = cls_data.__getitem__(i)\n",
    "print(label)\n",
    "plt.imshow(image.cpu()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# our data 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.ToTensor()])\n",
    "Rajan_preprocessed_dataset = ImageFolder(\n",
    "    root=\"data/Rajan_processed/\",\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set(Rajan_preprocessed_dataset.targets)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rajan_preprocessed_dataloader = DataLoader(Rajan_preprocessed_dataset, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=0)\n",
    "dataiter = iter(Rajan_preprocessed_dataloader)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "images, labels = dataiter.next()\n",
    "print(labels)\n",
    "plt.imshow(images.numpy()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# our data 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.ToTensor()])\n",
    "Parth_preprocessed_dataset = ImageFolder(\n",
    "    root=\"data/Parth_processed/\",\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set(Parth_preprocessed_dataset.targets)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parth_preprocessed_dataloader = DataLoader(Parth_preprocessed_dataset, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=0)\n",
    "dataiter_p = iter(Parth_preprocessed_dataloader)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "images, labels = dataiter_p.next()\n",
    "print(labels)\n",
    "print(np.max(images.numpy()[0][0]))\n",
    "plt.imshow(images.numpy()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMNIST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.EMNIST('/files/', train=True, download=True, split='letters',\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
