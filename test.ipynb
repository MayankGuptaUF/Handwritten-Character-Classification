{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.class_data import loaddata\n",
    "import numpy as np\n",
    "from math import ceil, floor\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ClassroomDataset(Dataset):\n",
    "    \n",
    "    @staticmethod\n",
    "    def standardize_image(image):\n",
    "        expected_shape = (50,50)\n",
    "        padding = [(0,0), (0,0)]\n",
    "        cropping = [(0,50), (0, 50)]\n",
    "        for d in [0,1]:\n",
    "            exp = expected_shape[d]\n",
    "            act = image.shape[d]\n",
    "            diff = exp - act\n",
    "            if diff > 0:\n",
    "                padding[d] = (ceil(diff / 2), floor(diff / 2))\n",
    "            elif diff < 0:\n",
    "                diff *= -1\n",
    "                cropping[d] = (ceil(diff / 2), 50 + floor(diff / 2))\n",
    "        image = np.pad(image, padding, 'constant', constant_values=0)\n",
    "        y = cropping[0]\n",
    "        x = cropping[1]\n",
    "        image = image[y[0]:y[1], x[0]:x[1]]\n",
    "        return image\n",
    "    \n",
    "    def to_include(self, i):\n",
    "        ret = False\n",
    "        mx = self.range_10[1]\n",
    "        mn = self.range_10[0]\n",
    "        if i % 10 < mx and i % 10 >= mn:\n",
    "            ret = True\n",
    "        return ret\n",
    "    \n",
    "    def __init__(self, range_10=[0, 10]):\n",
    "        path = \"data/class_data/train_data.pkl\"\n",
    "        cls_data = loaddata.load_pkl(path)\n",
    "        labels = np.load(\"data/class_data/finalLabelsTrain.npy\") \n",
    "        self.data = []\n",
    "        self.range_10 = range_10\n",
    "#         gpu = torch.cuda.is_available()\n",
    "        gpu = False\n",
    "        for i in range(len(cls_data)):\n",
    "            if self.to_include(i): # train set\n",
    "                image = np.array(cls_data[i])\n",
    "                image = image.astype(int)\n",
    "                image = self.standardize_image(image)\n",
    "                image = torch.from_numpy(np.array([image])).float()\n",
    "                label = torch.tensor(int(labels[i]))\n",
    "                if gpu:\n",
    "                    image = image.cuda()\n",
    "                    label = label.cuda()\n",
    "                pair = (image, label)\n",
    "                self.data.append(pair)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1a = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3a = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=10*10*12, out_features=300)\n",
    "        self.fc2 = nn.Linear(in_features=300, out_features=60)\n",
    "        self.fc3 = nn.Linear(in_features=60, out_features=9)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.relu(self.conv1(X))\n",
    "        X = self.relu(self.conv1a(X))\n",
    "        X = self.pool(self.relu(self.conv2(X)))\n",
    "        X = self.relu(self.conv3(X))\n",
    "        X = self.relu(self.conv3a(X))\n",
    "        X = self.pool(self.relu(self.conv4(X)))\n",
    "        X = X.view(-1, 10*10*12)\n",
    "        X = self.relu(self.fc1(X))\n",
    "        X = self.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return X\n",
    "\n",
    "def calculate_accuracy(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return acc\n",
    "\n",
    "def class_wise_accuracy(dataloader):\n",
    "    correct = {}\n",
    "    total = {}\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            for l in range(len(labels)):\n",
    "                label = int(labels[l].cpu().numpy())\n",
    "                pred = predicted[l]\n",
    "                if label in correct:\n",
    "                    correct[label] += int(pred == label)\n",
    "                    total[label] += 1\n",
    "                else:\n",
    "                    correct[label] = int(pred == label)\n",
    "                    total[label] = 1\n",
    "    acc = {}\n",
    "    for label in correct:\n",
    "        acc[label] = 100 * correct[label] / total[label]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = \"2019-12-02 13_47_01.pth\"\n",
    "PATH = \"./weights/\" + weights\n",
    "net = Net2().float()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_test = ClassroomDataset(range_10=[7,10])\n",
    "test_loader = DataLoader(cr_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.05208333333333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(dataloader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 94.58333333333333,\n",
       " 2: 95.02074688796681,\n",
       " 3: 95.81589958158996,\n",
       " 4: 94.91525423728814,\n",
       " 5: 91.06382978723404,\n",
       " 6: 96.29629629629629,\n",
       " 7: 97.52066115702479,\n",
       " 8: 95.08196721311475}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_wise_accuracy(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.array([-1, -2, -3, -4]) < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cr_train = ClassroomDataset(data_pkl_file, label_file)\n",
    "if use_MNIST:\n",
    "    transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.ToTensor()])\n",
    "    Parth_preprocessed_dataset = ImageFolder(\n",
    "        root=\"data/Parth_processed/\",\n",
    "        transform=transform\n",
    "    )\n",
    "    extra_train = Parth_preprocessed_dataset\n",
    "\n",
    "# Dividing data into 50% train, 40% val, 30% test\n",
    "scores = []\n",
    "for i in range(1):\n",
    "    print(\"Fold number\", i)\n",
    "    if use_larger_network:\n",
    "        net = Net2().float()\n",
    "    else:\n",
    "        net = Net().float()\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda()\n",
    "    loss_f = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    acc = []\n",
    "    for j in range(hyper_epochs):\n",
    "        val_loader = DataLoader(cr_train, batch_size=1, shuffle=True)\n",
    "        if use_MNIST:\n",
    "            to_cuda = torch.cuda.is_available()\n",
    "            _train(extra_train, epochs=ceil(sub_epochs / 3), batch_size=batch_size, to_cuda=to_cuda)\n",
    "        train_accuracy, val_accuracy = _train(cr_train, batch_size=batch_size, to_cuda=False, epochs=sub_epochs)\n",
    "        print(train_accuracy, val_accuracy)\n",
    "        acc.append((train_accuracy, val_accuracy))\n",
    "    scores.append(acc)\n",
    "\n",
    "p = \"weights/train.pth\"\n",
    "torch.save(net.state_dict(), p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
